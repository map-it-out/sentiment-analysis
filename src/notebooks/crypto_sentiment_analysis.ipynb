{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crypto News Sentiment Analysis\n",
    "\n",
    "This notebook analyzes sentiment from crypto news using NLTK's VADER sentiment analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install nltk requests pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Download VADER lexicon if not already downloaded\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"e:/My Stuff(s)/Mioaptut/fork/sentiment-analysis/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from typing import List, Optional, Dict, Any\n",
    "import json\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Classes and RSS Feed Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RSSItem:\n",
    "    \"\"\"Data class to store RSS feed item information\"\"\"\n",
    "    id: str\n",
    "    url: str\n",
    "    title: str\n",
    "    content_text: str\n",
    "    content_html: str\n",
    "    image: Optional[str]\n",
    "    published_date: Optional[datetime]\n",
    "    authors: List[Dict[str, str]]\n",
    "    attachments: List[Dict[str, str]]\n",
    "\n",
    "class RSSFeedError(Exception):\n",
    "    \"\"\"Custom exception for RSS feed errors\"\"\"\n",
    "    pass\n",
    "\n",
    "class RSSFeedScraper:\n",
    "    \"\"\"Scrapes and processes RSS feed data\"\"\"\n",
    "    def __init__(self, feed_url: str = \"https://rss.app/feeds/v1.1/t3OljJfE1OVl9TMq.json\"):\n",
    "        self.feed_url = feed_url\n",
    "\n",
    "    def fetch_feed(self) -> List[RSSItem]:\n",
    "        \"\"\"Fetch and parse RSS feed data\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.feed_url)\n",
    "            response.raise_for_status()\n",
    "            feed_data = response.json()\n",
    "            \n",
    "            return self._parse_items(feed_data.get('items', []))\n",
    "        except Exception as e:\n",
    "            raise RSSFeedError(f\"Failed to fetch RSS feed: {str(e)}\")\n",
    "\n",
    "    def _parse_date(self, date_str: str) -> Optional[datetime]:\n",
    "        \"\"\"Parse date string with multiple format attempts\"\"\"\n",
    "        if not date_str:\n",
    "            return None\n",
    "            \n",
    "        date_formats = [\n",
    "            '%Y-%m-%dT%H:%M:%S.%fZ',  # Standard ISO format with microseconds\n",
    "            '%Y-%m-%dT%H:%M:%SZ',     # ISO format without microseconds\n",
    "            '%Y-%m-%d %H:%M:%S',      # Basic datetime format\n",
    "            '%Y-%m-%d'                # Just date\n",
    "        ]\n",
    "        \n",
    "        for date_format in date_formats:\n",
    "            try:\n",
    "                return datetime.strptime(date_str, date_format)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return None\n",
    "\n",
    "    def _parse_items(self, items: List[dict]) -> List[RSSItem]:\n",
    "        \"\"\"Parse RSS items into RSSItem objects\"\"\"\n",
    "        parsed_items = []\n",
    "        for item in items:\n",
    "            published_date = self._parse_date(item.get('date_published'))\n",
    "            parsed_items.append(\n",
    "                RSSItem(\n",
    "                    id=item.get('id', ''),\n",
    "                    url=item.get('url', ''),\n",
    "                    title=item.get('title', ''),\n",
    "                    content_text=item.get('content_text', ''),\n",
    "                    content_html=item.get('content_html', ''),\n",
    "                    image=item.get('image'),\n",
    "                    published_date=published_date,\n",
    "                    authors=item.get('authors', []),\n",
    "                    attachments=item.get('attachments', [])\n",
    "                )\n",
    "            )\n",
    "        return parsed_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSSFeedSentimentAnalyzer:\n",
    "    \"\"\"Analyzes sentiment from RSS feed content\"\"\"\n",
    "    def __init__(self, feed_url: str = \"https://rss.app/feeds/v1.1/t3OljJfE1OVl9TMq.json\"):\n",
    "        self.scraper = RSSFeedScraper(feed_url)\n",
    "        self.sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def get_sentiment(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get sentiment analysis from RSS feed items\"\"\"\n",
    "        try:\n",
    "            # Fetch RSS items\n",
    "            items = self.scraper.fetch_feed()\n",
    "            \n",
    "            if not items:\n",
    "                return {\n",
    "                    \"value\": 0.0,\n",
    "                    \"classification\": \"Neutral\",\n",
    "                    \"interpretation\": \"No RSS items found\",\n",
    "                    \"items_analyzed\": 0,\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            # Calculate sentiment for each item\n",
    "            sentiments = []\n",
    "            for item in items:\n",
    "                # Analyze both title and content\n",
    "                title_scores = self.sia.polarity_scores(item.title)\n",
    "                content_scores = self.sia.polarity_scores(item.content_text)\n",
    "                \n",
    "                # Average the compound scores (giving more weight to title)\n",
    "                item_sentiment = (title_scores['compound'] * 0.6 + \n",
    "                                content_scores['compound'] * 0.4)\n",
    "                sentiments.append(item_sentiment)\n",
    "            \n",
    "            # Calculate average sentiment\n",
    "            avg_sentiment = sum(sentiments) / len(sentiments)\n",
    "            \n",
    "            # Get classification\n",
    "            if avg_sentiment < -0.6:\n",
    "                classification = \"Extreme Fear\"\n",
    "            elif avg_sentiment < -0.2:\n",
    "                classification = \"Fear\"\n",
    "            elif avg_sentiment < 0.2:\n",
    "                classification = \"Neutral\"\n",
    "            elif avg_sentiment < 0.6:\n",
    "                classification = \"Greed\"\n",
    "            else:\n",
    "                classification = \"Extreme Greed\"\n",
    "            \n",
    "            # Create interpretation\n",
    "            interpretation = f\"{classification} - RSS feed sentiment is \"\n",
    "            if avg_sentiment > 0:\n",
    "                interpretation += \"positive, showing optimistic market signals\"\n",
    "            elif avg_sentiment < 0:\n",
    "                interpretation += \"negative, showing pessimistic market signals\"\n",
    "            else:\n",
    "                interpretation += \"neutral, showing balanced market signals\"\n",
    "            \n",
    "            return {\n",
    "                \"value\": avg_sentiment,\n",
    "                \"classification\": classification,\n",
    "                \"interpretation\": interpretation,\n",
    "                \"items_analyzed\": len(items),\n",
    "                \"latest_item_date\": items[0].published_date.isoformat() if items[0].published_date else None,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "        except RSSFeedError as e:\n",
    "            return {\n",
    "                \"value\": 0.0,\n",
    "                \"classification\": \"Error\",\n",
    "                \"interpretation\": f\"Failed to analyze RSS feed: {str(e)}\",\n",
    "                \"items_analyzed\": 0,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Crypto News Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = RSSFeedSentimentAnalyzer(\"https://rss.app/feeds/v1.1/t3OljJfE1OVl9TMq.json\")\n",
    "\n",
    "# Get sentiment analysis\n",
    "sentiment = analyzer.get_sentiment()\n",
    "\n",
    "# Display results\n",
    "print(f\"Crypto News Sentiment Analysis:\")\n",
    "print(f\"Value: {sentiment['value']:.2f}\")\n",
    "print(f\"Classification: {sentiment['classification']}\")\n",
    "print(f\"Interpretation: {sentiment['interpretation']}\")\n",
    "print(f\"Items Analyzed: {sentiment['items_analyzed']}\")\n",
    "if sentiment.get('latest_item_date'):\n",
    "    print(f\"Latest Item Date: {sentiment['latest_item_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame for Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get items and their sentiments\n",
    "items = analyzer.scraper.fetch_feed()\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create list for DataFrame\n",
    "data = []\n",
    "for item in items:\n",
    "    title_scores = sia.polarity_scores(item.title)\n",
    "    content_scores = sia.polarity_scores(item.content_text)\n",
    "    weighted_sentiment = title_scores['compound'] * 0.6 + content_scores['compound'] * 0.4\n",
    "    \n",
    "    data.append({\n",
    "        'title': item.title,\n",
    "        'published_date': item.published_date,\n",
    "        'title_sentiment': title_scores['compound'],\n",
    "        'content_sentiment': content_scores['compound'],\n",
    "        'weighted_sentiment': weighted_sentiment,\n",
    "        'url': item.url\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values('published_date', ascending=False)\n",
    "\n",
    "# Display the first few articles with formatted dates\n",
    "display_df = df.copy()\n",
    "display_df['published_date'] = display_df['published_date'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "display_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot sentiment distributions\n",
    "sns.boxplot(data=df[['title_sentiment', 'content_sentiment', 'weighted_sentiment']])\n",
    "plt.title('Distribution of Crypto News Sentiment Scores')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(df['published_date'], df['weighted_sentiment'], alpha=0.6)\n",
    "\n",
    "# Customize the date format on x-axis\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=3))  # Show every 3 hours\n",
    "\n",
    "plt.title('Crypto News Sentiment Trend')\n",
    "plt.ylabel('Weighted Sentiment')\n",
    "plt.xlabel('Published Date')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
